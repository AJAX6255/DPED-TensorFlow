{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnyi/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy.misc\n",
    "from easydict import EasyDict as edict\n",
    "from DPED import *\n",
    "from utils import *\n",
    "from ops import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = edict()\n",
    "# training parameters\n",
    "config.batch_size = 50\n",
    "config.patch_size = 100\n",
    "config.mode = \"RGB\" #YCbCr\n",
    "config.channels = 3\n",
    "config.content_layer = 'relu5_4'\n",
    "config.learning_rate = 1e-4\n",
    "config.augmentation = True #data augmentation (flip, rotation)\n",
    "\n",
    "# weights for loss\n",
    "config.w_color = 1.2 # gaussian blur + mse (originally 0.1)\n",
    "config.w_texture = 1 # gan (originally 0.4)\n",
    "config.w_content = 2 # vgg19 (originally 1)\n",
    "config.w_tv = 1/400 # total variation (originally 400)\n",
    "\n",
    "# directories\n",
    "config.dataset_name = \"iphone\"\n",
    "config.train_path_phone = os.path.join(\"/home/johnyi/Downloads/dped\",str(config.dataset_name),\"training_data\",str(config.dataset_name),\"*.jpg\")\n",
    "config.train_path_dslr = os.path.join(\"/home/johnyi/Downloads/dped\",str(config.dataset_name),\"training_data/canon/*.jpg\")\n",
    "config.test_path_phone_patch = os.path.join(\"/home/johnyi/Downloads/dped\",str(config.dataset_name),\"test_data/patches\",str(config.dataset_name),\"*.jpg\")\n",
    "config.test_path_dslr_patch = os.path.join(\"/home/johnyi/Downloads/dped\",str(config.dataset_name),\"test_data/patches/canon/*.jpg\")\n",
    "config.test_path_phone_image = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/test/DPED/sample_images/original_images\",str(config.dataset_name),\"*.jpg\")\n",
    "config.test_path_dslr_image = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/test/DPED/sample_images/original_images/canon/*.jpg\")\n",
    "config.sample_dir = \"samples\"\n",
    "config.checkpoint_dir = \"checkpoint\"\n",
    "config.vgg_dir = \"../vgg_pretrained/imagenet-vgg-verydeep-19.mat\"\n",
    "config.log_dir = \"logs\"\n",
    "\n",
    "if not os.path.exists(config.checkpoint_dir):\n",
    "    os.makedirs(config.checkpoint_dir)\n",
    "if not os.path.exists(config.sample_dir):\n",
    "    os.makedirs(config.sample_dir)\n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.makedirs(config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: iphone, 160471 image pairs\n",
      "160471 image pairs loaded! setting took: 89.3427s\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_phone, dataset_dslr = load_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed building generator. Number of variables: 26\n",
      "Completed building discriminator. Number of variables: 22\n"
     ]
    }
   ],
   "source": [
    "# build DPED model\n",
    "tf.reset_default_graph()\n",
    "# uncomment this when only trying to test the model\n",
    "dataset_phone = []\n",
    "dataset_dslr = []\n",
    "sess = tf.Session()\n",
    "model = DPED(sess, config, dataset_phone, dataset_dslr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Discriminator training starts from beginning\n",
      "Iteration 0, runtime: 0.350 s, discriminator loss: 1.376139\n",
      "Discriminator test accuracy: phone: 126/200, dslr: 121/200\n",
      "Iteration 2000, runtime: 73.813 s, discriminator loss: 0.955353\n",
      "Discriminator test accuracy: phone: 119/200, dslr: 183/200\n",
      "Iteration 4000, runtime: 147.454 s, discriminator loss: 1.039908\n",
      "Discriminator test accuracy: phone: 175/200, dslr: 143/200\n",
      "Iteration 6000, runtime: 221.263 s, discriminator loss: 0.528191\n",
      "Discriminator test accuracy: phone: 174/200, dslr: 175/200\n",
      "Iteration 8000, runtime: 294.902 s, discriminator loss: 0.675135\n",
      "Discriminator test accuracy: phone: 177/200, dslr: 165/200\n",
      "pretraining complete\n"
     ]
    }
   ],
   "source": [
    "# pretrain discriminator with (phone, dslr) pairs\n",
    "model.pretrain_discriminator(load = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoints from  checkpoint/iphone\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/iphone/DPED\n",
      " [*] Load SUCCESS\n",
      "Discriminator test accuracy: phone: 160/200, dslr: 130/200\n"
     ]
    }
   ],
   "source": [
    "# test discriminator performance for (phone, dslr) pair\n",
    "model.test_discriminator(200, load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoints from  checkpoint/iphone\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/iphone/DPED\n",
      " [*] Load SUCCESS\n",
      "Iteration 0, runtime: 2.042 s, generator loss: 55.007935\n",
      "Loss per component: color 14.718228, texture 12.986241, content 11.960189, tv 175.774673\n",
      "Dricriminator test accuracy: phone: 93/200, dslr: 198/200, enhanced: 149/200\n",
      "(runtime: 2.144 s) Average test PSNR for 200 test image patches: phone-enhanced 11.953, dslr-enhanced 11.768\n",
      "Iteration 1000, runtime: 442.805 s, generator loss: 19.725391\n",
      "Loss per component: color 1.934178, texture 1.590602, content 6.660661, tv 996.982178\n",
      "Dricriminator test accuracy: phone: 143/200, dslr: 159/200, enhanced: 144/200\n",
      "(runtime: 2.125 s) Average test PSNR for 200 test image patches: phone-enhanced 22.126, dslr-enhanced 20.383\n",
      "Iteration 2000, runtime: 884.879 s, generator loss: 23.790648\n",
      "Loss per component: color 2.261600, texture 2.301839, content 8.285510, tv 881.546875\n",
      "Dricriminator test accuracy: phone: 155/200, dslr: 142/200, enhanced: 140/200\n",
      "(runtime: 2.260 s) Average test PSNR for 200 test image patches: phone-enhanced 22.474, dslr-enhanced 20.459\n",
      "Iteration 3000, runtime: 1327.342 s, generator loss: 22.120274\n",
      "Loss per component: color 2.559082, texture 1.350731, content 7.730587, tv 894.987244\n",
      "Dricriminator test accuracy: phone: 181/200, dslr: 132/200, enhanced: 153/200\n",
      "(runtime: 2.164 s) Average test PSNR for 200 test image patches: phone-enhanced 22.378, dslr-enhanced 20.275\n",
      "Iteration 4000, runtime: 1770.185 s, generator loss: 17.669121\n",
      "Loss per component: color 2.063137, texture 1.034120, content 6.069452, tv 808.133301\n",
      "Dricriminator test accuracy: phone: 174/200, dslr: 108/200, enhanced: 169/200\n",
      "(runtime: 2.095 s) Average test PSNR for 200 test image patches: phone-enhanced 20.836, dslr-enhanced 20.736\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-58c999e3fd7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train generator & discriminator together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/deeplearning/research/ICCV17-DPED/DPED.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mphone_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdslr_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_phone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_dslr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhanced_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhanced_patch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphone_patch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mphone_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdslr_patch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdslr_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_optimizer\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphone_patch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0menhanced_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdslr_patch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdslr_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/research/ICCV17-DPED/utils.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(dataset_phone, dataset_dslr, config, start)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m#dslr_batch[i,:,:,:] = dslr_patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mphone_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphone_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mdslr_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdslr_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mphone_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdslr_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/research/ICCV17-DPED/ops.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train generator & discriminator together\n",
    "model.train(load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoints from  checkpoint/iphone\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/iphone/DPED\n",
      " [*] Load SUCCESS\n",
      "Dricriminator test accuracy: phone: 158/200, dslr: 134/200, enhanced: 148/200\n",
      "(runtime: 2.716 s) Average test PSNR for 200 random test image patches: phone-enhanced 21.092, dslr-enhanced 20.136\n",
      "(runtime: 100.793 s) Average test PSNR for 14 random full test images: phone-enhanced 21.092\n"
     ]
    }
   ],
   "source": [
    "# test trained model\n",
    "model.test_generator(200, 14, load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
